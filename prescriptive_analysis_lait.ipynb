{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chargement des Packages et utilitaires nécessaires \n",
    "# !pip install -q gcsfs shap optuna graphviz lightgbm\n",
    "\n",
    "import optuna\n",
    "import pandas as pd, numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "from graphviz import Source\n",
    "from IPython.display import SVG\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Importation de la base de données \n",
    "df_lait=pd.read_csv('BD_COUT_LAIT_STATS_NEW_3POP_CONTROL.csv',sep=';')\n",
    "df_lait.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Liste des colonnes \n",
    "print(df_lait.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_lait.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sélection des variables\n",
    "\n",
    "df_lait=df_lait[['DEP', 'IDQ', 'v2_1', 'SYS2', 'Prop_produit_lait', 'ANNEE_Prod', 'NBR_TRIM3', 'NBR_TRIM4', 'NBR_TRIM1', 'SFP', 'NBR_VL', 'LAIT_VENDU', 'NBR_UMO_EXPT',\n",
    "                'NBR_UMO_SAL', 'LAIT_VENDU_UMOREM','SALAIRE','FRAIS_DIVERS','BATIMENT_INST','FONCIER_CAPITAL', 'FRAIS_FINANCIERS', 'REM_CAPITAUX_PROPRE','MECA','FRAIS_ELEVAGE', 'APPROV_SURFACE', 'APPROV_ANIMAUX','TOT_AMORT','PRODUIT_LAIT', 'PRODUITS_JOINTS',\n",
    "                'REM_PAR_PRODUIT_SMIC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lait['v2_1']=df_lait['v2_1'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Définition du positionnement \n",
    "#if pd.notnull(df_lait['SFP']): \n",
    "    \n",
    "df_lait['LAIT_VENDU_SFP']=df_lait['LAIT_VENDU']/df_lait['SFP']\n",
    "\n",
    "df_lait['LAIT_VENDU_NB_VL']=df_lait['LAIT_VENDU']/df_lait['NBR_VL']\n",
    "\n",
    "df_lait['Prix_lait']=(df_lait['PRODUIT_LAIT']*1000/df_lait['LAIT_VENDU'])*1000\n",
    "\n",
    "df_lait.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_lait=df_lait.fillna(0)\n",
    "\n",
    "### Variables dummies montagne et plaine. \n",
    "#cat_names = {1:'Plaine', 3:'Montagne'}\n",
    "#for elem in df_lait['v2_1'].unique():\n",
    "    #df_lait[cat_names[elem]] = df_lait['v2_1'] == elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_lait[df_lait['SFP']==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_lait['Prix_lait'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_lait['LAIT_VENDU'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_lait['PRODUIT_LAIT'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lait.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lait=df_lait.rename(columns={'DEP':'ID: departement','IDQ':'ID: dossier','ANNEE_Prod':'ID: annee',\n",
    "                               'FRAIS_DIVERS':'Pratiques_elevage: frais_divers','Prop_produit_lait':'Pratiques_elevage: taux_specialisation','Prop_produit_lait':'Pratiques_elevage: taux_specialisation',\n",
    "                               'FRAIS_ELEVAGE':'Pratiques_elevage: frais_elevage','APPROV_SURFACE':'Pratiques_elevage: approvisionnement_surfaces','APPROV_ANIMAUX':'Pratiques_elevage: approvisionnement_animaux',\n",
    "                               'PRODUIT_LAIT':'Pratiques_elevage: produit_lait','PRODUIT_JOINTS':'Pratiques_elevage: produit_joints',\n",
    "                               'FONCIER_CAPITAL':'Dynamique_structurelle: foncier_capital','FRAIS_FINANCIERS':'Dynamique_structurelle: frais_financiers','REM_CAPITAUX_PROPRE':'Dynamique_structurelle: remunaration_capitaux_propres',\n",
    "                               'SALAIRE':'Dynamique_structurelle: salaires','LAIT_VENDU_UMOREM':'Dynamique_structurelle: lait_vendu_umo_remunere','MECA':'Dynamique_structurelle: mecanisation',\n",
    "                               'BATIMENT_INST':'Dynamique_structurelle: batiment_installation','TOT_AMORT':'Dynamique_structurelle: total_amortissement',\n",
    "                               'NBR_UMO_EXPT':'Dimension: umo_exploitant','NBR_VL':'Dimension: taille_troupeau','SFP':'Dimension: surface_fouragere',\n",
    "                               'LAIT_VENDU_NB_VL':'Positionnement: lait_vendu_par_vl','LAIT_VENDU_SFP':'Positionnement: lait_vendu_par_sfp','v2_1':'Invariant: montagne_plaine','SYS2':'Bio: bio_conventionnel',\n",
    "                               'NBR_TRIM3':'Invariant: du_trimestre_3','NBR_TRIM4':'Invariant: du_trimestre_4', 'NBR_TRIM1':'Invariant: du_trimestre_1',\n",
    "                               'REM_PAR_PRODUIT_SMIC':'Cible: remuneration_par_produit_smic'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders=['ID','Invariant','Bio','Dimension','Dynamique_structurelle','Pratiques_elevage','Positionnement','Cible']\n",
    "df_lait=pd.concat([df_lait.filter(regex=f'{order}:') for order in orders],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_lait.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_lait.shape\n",
    "df_lait=df_lait[df_lait['Positionnement: lait_vendu_par_sfp']<20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_lait.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_lait.describe(include=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lait=df_lait[df_lait['Pratiques_elevage: frais_elevage']>0]\n",
    "df_lait.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dessine la graphe d'Elbow pour trouver le nombre idéal de clusters \n",
    "def findbestclusters(data,maxclusters=30,minclusters=2):\n",
    "  Sum_of_squared_distances = []\n",
    "  K = range(minclusters,maxclusters)\n",
    "  for k in K:\n",
    "      km = KMeans(n_clusters=k, random_state=49)\n",
    "      km = km.fit(data)\n",
    "      Sum_of_squared_distances.append(km.inertia_)\n",
    "  plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "  plt.xlabel('k')\n",
    "  plt.ylabel('Sum_of_squared_distances')\n",
    "  plt.title('Elbow Method For Optimal k')\n",
    "  plt.show()\n",
    "\n",
    "  sil = []\n",
    "  # dissimilarity would not be defined for a single cluster, thus, minimum number of clusters should be 2\n",
    "  for k in range(minclusters+1, maxclusters+1):\n",
    "    kmeans = KMeans(n_clusters = k).fit(data)\n",
    "    labels = kmeans.labels_\n",
    "    sil.append({'k':k,'score':silhouette_score(data, labels, metric = 'euclidean')})\n",
    "  sil=pd.DataFrame(sil)\n",
    "  sil.plot(x='k',y='score')\n",
    "  return sil[sil.score==sil.score.max()].iloc[0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Le clustering \n",
    "n_clusters=findbestclusters(df_lait.filter(regex='Positionnement'),maxclusters=10,minclusters=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_clusters=5\n",
    "km = KMeans(n_clusters=n_clusters, random_state=49)\n",
    "y=km.fit_predict(df_lait.filter(regex='Positionnement'))\n",
    "fig, ax = plt.subplots(figsize=(10,8)) \n",
    "sns.scatterplot(data=df_lait, x='Positionnement: lait_vendu_par_sfp',y='Positionnement: lait_vendu_par_vl',hue=y,ax=ax,palette=\"Set2\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfclustered=df_lait.copy()\n",
    "dfclustered['cluster']=y\n",
    "dfclustered.to_csv('dfclustered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dfclustered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_3d(dfclustered, x='Positionnement: lait_vendu_par_vl',y='Positionnement: lait_vendu_par_sfp', z='Cible: remuneration_par_produit_smic',\n",
    "              color='cluster')\n",
    "fig.show(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#détermination des critères de clusters\n",
    "sns.countplot(x='cluster',data=dfclustered, palette='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for c in dfclustered.columns:\n",
    "  fig, ax = plt.subplots(figsize=(4,4)) \n",
    "  sns.boxplot(x=\"cluster\", y=c, data=dfclustered,\n",
    "                   ax=ax, palette='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting the dummies of Clusters \n",
    "cat_names = {0:'Cluster0', 1:'Cluster1',2:'Cluster2',3:'Cluster3',4:'Cluster4'}\n",
    "for elem in dfclustered['cluster'].unique():\n",
    "    dfclustered[cat_names[elem]] = dfclustered['cluster'] == elem\n",
    "    \n",
    "dfclustered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "values=dfclustered.groupby('cluster').mean()\n",
    "\n",
    "values=pd.DataFrame(MinMaxScaler().fit_transform(values),columns=values.columns)\n",
    "\n",
    "categories = values.columns\n",
    "for index, row in values.iterrows():\n",
    "  fig = go.Figure()\n",
    "  fig.add_trace(go.Scatterpolar(\n",
    "        r=list(row.values),\n",
    "        theta=categories,\n",
    "        fill='toself',\n",
    "        name=str(index),\n",
    "        line_color='rgb'+str(sns.color_palette(\"Set2\",8)[index])\n",
    "  ))\n",
    "  fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for cluster in dfclustered.cluster.unique():\n",
    "  print(cluster)\n",
    "  cluster0=dfclustered.copy()\n",
    "  cluster0['cluster']=cluster0['cluster']==cluster\n",
    "  cluster0=cluster0.drop(['ID: departement','ID: dossier','ID: annee'],1)\n",
    "  X=cluster0.drop('cluster',1)\n",
    "  X=cluster0.filter(regex='Positionnement')\n",
    "  y=cluster0.cluster\n",
    "  estimator = DecisionTreeClassifier(max_depth=3)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "  estimator.fit(X_train, y_train)\n",
    "  estimator.predict(X_test)\n",
    "  print(estimator.score(X_test, y_test))\n",
    "  graph = Source(tree.export_graphviz(estimator, out_file=None\n",
    "    , feature_names=X.columns\n",
    "    , class_names=True\n",
    "    , filled = True))\n",
    "  display(SVG(graph.pipe(format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Caractérisations de ces classes par rapport à leurs pratiques d'élevages \n",
    "for cluster in dfclustered.cluster.unique():\n",
    "  print(cluster)\n",
    "  cluster0=dfclustered.copy()\n",
    "  cluster0['cluster']=cluster0['cluster']==cluster\n",
    "  cluster0=cluster0.drop(['ID: departement','ID: dossier','ID: annee'],1)\n",
    "  X=cluster0.drop('cluster',1)\n",
    "  X=cluster0.filter(regex='Pratiques_elevage')\n",
    "  y=cluster0.cluster\n",
    "  estimator = DecisionTreeClassifier(max_depth=3)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "  estimator.fit(X_train, y_train)\n",
    "  estimator.predict(X_test)\n",
    "  print(estimator.score(X_test, y_test))\n",
    "  graph = Source(tree.export_graphviz(estimator, out_file=None\n",
    "    , feature_names=X.columns\n",
    "    , class_names=True\n",
    "    , filled = True))\n",
    "  display(SVG(graph.pipe(format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "###### Caractérisation des types de pratiques d'élevages\n",
    "## Passons d'abord certaines les  variables de positionnement en pratiques d'élevage. \n",
    "df_lait2=df_lait.rename(columns={'Positionnement: lait_vendu_par_vl':'Pratiques_elevage: lait_vendu_par_vl',\n",
    "       'Positionnement: lait_vendu_par_sfp':'Pratiques_elevage: lait_vendu_par_sfp'})\n",
    "\n",
    "df_lait2['Pratiques_elevage: charges_elevage']= df_lait2['Pratiques_elevage: frais_divers'] + df_lait2['Pratiques_elevage: frais_elevage'] + df_lait2['Pratiques_elevage: approvisionnement_surfaces'] + df_lait2['Pratiques_elevage: approvisionnement_animaux']\n",
    "\n",
    "df_lait2=df_lait2.drop(columns=['Pratiques_elevage: frais_divers','Pratiques_elevage: frais_elevage','Pratiques_elevage: approvisionnement_surfaces','Pratiques_elevage: approvisionnement_animaux'])\n",
    "orders=['ID','Invariant','Bio','Dimension','Dynamique_structurelle','Pratiques_elevage','Positionnement','Cible']\n",
    "df_lait2=pd.concat([df_lait2.filter(regex=f'{order}:') for order in orders],1)\n",
    "df_lait2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_lait.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## Clustering des pratiques d'élevages \n",
    "n_clusters2=findbestclusters(df_lait2.filter(regex='Pratiques_elevage'),maxclusters=15,minclusters=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_clusters=6\n",
    "km = KMeans(n_clusters=n_clusters, random_state=49)\n",
    "y=km.fit_predict(df_lait2.filter(regex='Pratiques_elevage'))\n",
    "fig, ax = plt.subplots(figsize=(10,8)) \n",
    "sns.scatterplot(data=df_lait2, x='Pratiques_elevage: charges_elevage',y='Pratiques_elevage: lait_vendu_par_vl',hue=y,ax=ax,palette=\"Set2\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dfclustered2=df_lait2.copy()\n",
    "dfclustered2['cluster']=y\n",
    "dfclustered2.to_csv('dfclustered2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dfclustered2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Caractérisations de ces classes par rapport à leurs pratiques d'élevages \n",
    "for cluster in dfclustered2.cluster.unique():\n",
    "  print(cluster)\n",
    "  cluster0=dfclustered2.copy()\n",
    "  cluster0['cluster']=cluster0['cluster']==cluster\n",
    "  cluster0=cluster0.drop(['ID: departement','ID: dossier','ID: annee'],1)\n",
    "  X=cluster0.drop('cluster',1)\n",
    "  X=cluster0.filter(regex='Pratiques_elevage')\n",
    "  y=cluster0.cluster\n",
    "  estimator = DecisionTreeClassifier(max_depth=3)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "  estimator.fit(X_train, y_train)\n",
    "  estimator.predict(X_test)\n",
    "  print(estimator.score(X_test, y_test))\n",
    "  graph = Source(tree.export_graphviz(estimator, out_file=None\n",
    "    , feature_names=X.columns\n",
    "    , class_names=True\n",
    "    , filled = True))\n",
    "  display(SVG(graph.pipe(format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfclustered[dfclustered['ID: departement']==76].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dfclustered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Enlever les variables de positonnement \n",
    "df_lait_cf=dfclustered.drop(columns=['Positionnement: lait_vendu_par_sfp','Positionnement: lait_vendu_par_vl'],axis=1)\n",
    "df_lait_cf=dfclustered.drop(columns=['ID: departement','ID: dossier','ID: annee'],axis=1) \n",
    "\n",
    "### Recodage de quelques variables \n",
    "\n",
    "df_lait_cf['Invariant: du_trimestre_3'] = np.where(df_lait_cf['Invariant: du_trimestre_3'] == 1, \"oui\", \"non\")\n",
    "df_lait_cf['Invariant: du_trimestre_4'] = np.where(df_lait_cf['Invariant: du_trimestre_4'] == 1, \"oui\", \"non\")\n",
    "df_lait_cf['Invariant: du_trimestre_1'] = np.where(df_lait_cf['Invariant: du_trimestre_1'] == 1, \"oui\", \"non\")\n",
    "df_lait_cf['Invariant: montagne_plaine'] = np.where(df_lait_cf['Invariant: montagne_plaine'] == 1, \"plaine\", \"montagne\")\n",
    "df_lait_cf['Bio: bio_conventionnel'] = np.where(df_lait_cf['Bio: bio_conventionnel'] == 1, \"oui\", \"non\")\n",
    "\n",
    "df_lait_cf.loc[df_lait_cf['cluster'] == 0, 'cluser_label'] = 'cluster_0'\n",
    "df_lait_cf.loc[df_lait_cf['cluster'] == 1, 'cluser_label'] = 'cluster_1'\n",
    "df_lait_cf.loc[df_lait_cf['cluster'] == 2, 'cluser_label'] = 'cluster_2'\n",
    "df_lait_cf.loc[df_lait_cf['cluster'] == 3, 'cluser_label'] = 'cluster_3'\n",
    "df_lait_cf.loc[df_lait_cf['cluster'] == 4, 'cluser_label'] = 'cluster_4'\n",
    "\n",
    "df_lait_cf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_lait_cf=df_lait_cf.drop(columns=['cluster'],axis=1) \n",
    "df_lait_cf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Suite des analyses, prédiction de la variables cibles rémunération permise par la rémunération permise par le produit. Package de Microsoft. DiCE. \n",
    "import dice_ml\n",
    "from dice_ml import Dice\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_name='Cible: remuneration_par_produit_smic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lait_cf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lait_cf=df_lait_cf.drop(columns=['Positionnement: lait_vendu_par_sfp','Positionnement: lait_vendu_par_vl'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lait_cf=df_lait_cf.drop(columns=['Pratiques_elevage: frais_divers'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lait_cf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_lait_cf['cluster']=df_lait_cf['cluster'].astype('category')\n",
    "#df_lait_cf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lait_cf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=dfclustered[outcome_name]\n",
    "continuous_features1 = df_lait_cf.filter(regex='Dimension').columns.tolist()\n",
    "continuous_features2 = df_lait_cf.filter(regex='Dynamique_structurelle').columns.tolist()\n",
    "continuous_features3 = df_lait_cf.filter(regex='Pratiques_elevage').columns.tolist()\n",
    "continuous_features_df_lait_cf=continuous_features1+continuous_features2+continuous_features3\n",
    "continuous_features_df_lait_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Density plots\n",
    "sns.distplot(df_lait_cf['Cible: remuneration_par_produit_smic'], hist=True, kde=True, \n",
    "                 bins=int(180/5), color = 'darkblue', \n",
    "                 hist_kws={'edgecolor':'black'},\n",
    "                 kde_kws={'linewidth': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_lait_cf['Dimension: umo_exploitant'], df_lait_cf['Cible: remuneration_par_produit_smic'], 'o', color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lait_cf['cluster']=df_lait_cf['cluster'].astype('int')\n",
    "\n",
    "categorical_features=['cluster']\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import HuberRegressor, RANSACRegressor\n",
    "\n",
    "# Split data into train and test\n",
    "datasetX = df_lait_cf.drop(outcome_name, axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(datasetX, \n",
    "                                                    target, \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=21)\n",
    "#categorical_features=x_train.columns.difference(numerical) \n",
    "categorical_features = x_train.columns.difference(continuous_features_df_lait_cf) \n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "transformations = ColumnTransformer(transformers=[('num', numeric_transformer, continuous_features_df_lait_cf),('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "reg_lait = Pipeline(steps=[('preprocessor', transformations),\n",
    "                           ('regressor', MLPRegressor(hidden_layer_sizes=(400,500,), activation=\"relu\" ,random_state=1))])\n",
    "model_lait=reg_lait.fit(x_train, y_train)\n",
    "reg_lait.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = reg_lait.predict(x_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dfclustered_new=dfclustered.copy()\n",
    "\n",
    "cat_names = {0:'Cluster0', 1:'Cluster1',2:'Cluster2',3:'Cluster3',4:'Cluster4'}\n",
    "for elem in dfclustered_new['cluster'].unique():\n",
    "    dfclustered_new[cat_names[elem]] = dfclustered_new['cluster'] == elem\n",
    "    #dfclustered_new[cat_names[elem]].astype(int)\n",
    "\n",
    "dfclustered_new['Cluster0']=dfclustered_new['Cluster0'].astype(int)\n",
    "dfclustered_new['Cluster1']=dfclustered_new['Cluster1'].astype(int)\n",
    "dfclustered_new['Cluster2']=dfclustered_new['Cluster2'].astype(int)\n",
    "dfclustered_new['Cluster3']=dfclustered_new['Cluster3'].astype(int)\n",
    "dfclustered_new['Cluster4']=dfclustered_new['Cluster4'].astype(int)\n",
    "\n",
    "dfclustered_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dfclustered_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "random_state = 7\n",
    "X = dfclustered_new.drop(['Cible: remuneration_par_produit_smic','cluster','ID: departement','ID: dossier','ID: annee','Positionnement: lait_vendu_par_sfp','Positionnement: lait_vendu_par_vl'],axis=1)\n",
    "y=dfclustered_new['Cible: remuneration_par_produit_smic']\n",
    "\n",
    "X=X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "model=lgb.LGBMRegressor(n_estimators=50000)\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=20,verbose=False)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = model.predict(X_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lait_cf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Counterfactual explanation \n",
    "d_lait = dice_ml.Data(dataframe=df_lait_cf, continuous_features=continuous_features_df_lait_cf, outcome_name=outcome_name)\n",
    "# We provide the type of model as a parameter (model_type)\n",
    "m_lait = dice_ml.Model(model=model_lait, backend=\"sklearn\", model_type='regressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_genetic_lait = Dice(d_lait, m_lait, method=\"genetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "r1 = re.compile('Pratiques_elevage*')\n",
    "r2 = re.compile('Dynamique_structurelle*')\n",
    "r3 = re.compile('Dimension*')\n",
    "r4 = re.compile('Invariant*')\n",
    "r5 = re.compile('Bio*')\n",
    "r6 = re.compile('cluster*')\n",
    "features_vary=list(filter(r1.match, continuous_features_df_lait_cf)) + list(filter(r2.match, continuous_features_df_lait_cf)) + list(filter(r3.match, continuous_features_df_lait_cf)) + list(filter(r5.match, continuous_features_df_lait_cf))\n",
    "query_instances_lait = datasetX[2:3]\n",
    "genetic_lait = exp_genetic_lait.generate_counterfactuals(query_instances_lait, \n",
    "                                                             total_CFs=3, \n",
    "                                                             features_to_vary=features_vary,\n",
    "                                                             proximity_weight=2.5, diversity_weight=1,\n",
    "                                                             desired_range=[1,2])\n",
    "genetic_lait.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=genetic_lait.cf_examples_list[0].final_cfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
