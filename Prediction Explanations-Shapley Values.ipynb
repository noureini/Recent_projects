{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import dataiku\n",
    "import pandas as pd, numpy as np\n",
    "from dataiku import pandasutils as pdu\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read recipe inputs\n",
    "alert_PREDICT_EXPLANATION_prepared = dataiku.Dataset(\"ALERT_PREDICT_EXPLANATION_prepared\")\n",
    "alert_PREDICT_EXPLANATION_prepared_df = alert_PREDICT_EXPLANATION_prepared.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##the data base\n",
    "alert_PREDICT_EXPLANATION_prepared_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computing the sum of shapley values for each row\n",
    "mean_ln_odd_pred=alert_PREDICT_EXPLANATION_prepared_df['ln_odd_pred_prob'].mean()\n",
    "alert_PREDICT_EXPLANATION_prepared_df['Sum_shapley']=alert_PREDICT_EXPLANATION_prepared_df['ln_odd_pred_prob']-mean_ln_odd_pred\n",
    "alert_PREDICT_EXPLANATION_prepared_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main columns of interest\n",
    "cols=[0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "X_all=alert_PREDICT_EXPLANATION_prepared_df[alert_PREDICT_EXPLANATION_prepared_df.columns[cols]]\n",
    "X_all=X_all.set_index('CERFRANCE')\n",
    "X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to transform shapley values into predicted probability variation\n",
    "\n",
    "def shap2deltaprob(features,\n",
    "                   shap_df,\n",
    "                   shap_sum,\n",
    "                   probas,\n",
    "                   func_shap2probas):\n",
    "    '''\n",
    "    map shap to Δ probabilities\n",
    "    --- input ---\n",
    "    :features: list of strings, names of features\n",
    "    :shap_df: pd.DataFrame, dataframe containing shap values\n",
    "    :shap_sum: pd.Series, series containing shap sum for each observation\n",
    "    :probas: pd.Series, series containing predicted probability for each observation\n",
    "    :func_shap2probas: function, maps shap to probability (for example interpolation function)\n",
    "    --- output ---\n",
    "    :out: pd.Series or pd.DataFrame, Δ probability for each shap value\n",
    "    '''\n",
    "    # 1 feature\n",
    "    if type(features) == str or len(features) == 1:\n",
    "        return probas - (shap_sum - shap_df[features]).apply(func_shap2probas)\n",
    "    # more than 1 feature\n",
    "    else:\n",
    "        return shap_df[features].apply(lambda x: shap_sum - x).apply(func_shap2probas)\\\n",
    "                .apply(lambda x: probas - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inputs for the function defined above\n",
    "shap_sum=alert_PREDICT_EXPLANATION_prepared_df['Sum_shapley']\n",
    "cols1=[0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "shap_df=alert_PREDICT_EXPLANATION_prepared_df[alert_PREDICT_EXPLANATION_prepared_df.columns[cols1]]\n",
    "probas=alert_PREDICT_EXPLANATION_prepared_df['proba_1']\n",
    "shap_df=shap_df.set_index('CERFRANCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas=pd.Series(alert_PREDICT_EXPLANATION_prepared_df['proba_1'].tolist(),index=X_all.index)\n",
    "shap_sum=pd.Series(alert_PREDICT_EXPLANATION_prepared_df['Sum_shapley'].tolist(),index=X_all.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build interpolation function to map shap into probability\n",
    "shap_sum_sort = shap_sum.sort_values()\n",
    "probas_sort = probas[shap_sum_sort.index]\n",
    "\n",
    "intp = interp1d(shap_sum_sort,\n",
    "                probas_sort,\n",
    "                bounds_error = False,\n",
    "                fill_value = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regarder l'allure de la courbe\n",
    "plt.scatter(shap_sum_sort, probas_sort,color='blue',zorder=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show Δ probabilities\n",
    "temp = shap2deltaprob(X_all.columns.tolist(),\n",
    "                      shap_df,\n",
    "                      shap_sum,\n",
    "                      probas,\n",
    "                      func_shap2probas=intp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['CERFRANCE']=temp.index\n",
    "temp['Shap_sum']=shap_sum\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alert_PREDICT_EXPLANATION_prepared_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_norm=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "temp2=temp[temp.columns[col_to_norm]]\n",
    "\n",
    "temp_normalized=temp2.apply(lambda x:(x-x.mean())/x.std())\n",
    "\n",
    "temp_normalized.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_norm2=X_all.apply(lambda x:(x-x.mean())/x.std())\n",
    "temp_norm2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fillna=X_all.fillna(0)\n",
    "temp_fillna.head()\n",
    "temp_fillna_norm=temp_fillna.apply(lambda x:(x-x.mean())/x.std())\n",
    "temp_fillna_norm['CERFRANCE']=temp_fillna_norm.index\n",
    "temp_fillna_norm['Shap_sum']=shap_sum\n",
    "temp_fillna_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 rows successfully written (zHISg9I1LN)\n"
     ]
    }
   ],
   "source": [
    "# Write recipe outputs\n",
    "alert_PREDICT_EXPLANATIONS_DATA_df =temp_fillna_norm # For this sample code, simply copy input to output\n",
    "alert_PREDICT_EXPLANATIONS_DATA = dataiku.Dataset(\"ALERT_PREDICT_EXPLANATIONS_DATA\")\n",
    "alert_PREDICT_EXPLANATIONS_DATA.write_with_schema(temp_fillna_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "associatedRecipe": "compute_ALERT_PREDICT_EXPLANATIONS_DATA",
  "creator": "admin",
  "customFields": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "tags": [
   "recipe-editor"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
